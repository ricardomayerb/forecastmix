---
title: "The basics, with two models"
author: "Ricardo Mayer"
date: "12/6/2018"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_knit$set(root.dir = rprojroot::find_rstudio_root_file())
```

```{r source-and-lib, message=FALSE, warning=FALSE}
source('./R/combinations_functions.R')
```



We will start with a ready to use data set with quarterly, stationary series than can be used in an ordinary VAR, and we will not explain how the data munging is done. In particular, we will *not* discuss the following important points:
    - how the data was obtained
    - how monthly data was converted to quaterly frequency
    - how monthly data was *extended* to complete its current final quarter
    - how (potentially) exogenous data was forecasted in order to make it available to produce conditional forecasts
    - how each series was transformed using seasonal and oridinary differeces to render them stationary
    
All those points are discussed in the data preparation document, see *here*

## VAR-ready data set
    
We will use domestic data from Uruguay and few series that can be considered exogenous to teh country's economic activity, namely indexes of economic activity in USA, EU, Asia, Brazil and Argentina (we can choose later whether to treat a given series as exogeous or exogenous when specifying our VARs)

First, we identify the country (Uruguay) and vintage (second vintage of data gathered in 2018) Then we load the data, put it in quarterly form and print their names 


```{r loading_data}
country <- "Uruguay"
forecast_exercise_year <- 2018
forecast_exercise_number <- 3
var_output_path <- paste0("./analysis/VAR_output//edd_exercises/", forecast_exercise_year, 
                            "_exercise_", forecast_exercise_number, "/")

all_data_for_VAR_estimation  <- readRDS(paste0(var_output_path, "VAR_data_", country, ".rds"))
# print(colnames(VAR_data_for_estimation))
```

In this case, we used a  "diff-yoy" transformation for the real GDP series (first, take seasonal differences on the quarterly series and then ordinary differences on the result) and, as consequence the predictions about real gdp coming straight out the VAR will be forecasts in this metric, too. It is up to us to transform those predicted values into, say, year-on-year proportional changes.    

## Propose, test and keep or discard specifications

Given a data set with stationary variables, obteined in the previous section, a VAR especification consists in a set of endogenous variables, exogenous variables, a maximum lag value and a restriction over coefficients. Lets begin with the following specification

  - set of endogenous variables: rgdp, imp_intermediate, rpc
  - set of exogenous variables: none  (we will add them later)
  - a value for the maximum lag: 5
  - a restriction over coefficients: none or, as we will see, setting our threshold to zero. 

```{r inital_var_specification}
subset_of_variables <- c("rgdp", "imp_intermediate", "rpc")
var_data <- all_data_for_VAR_estimation[, subset_of_variables]
var_data <- na.omit(var_data)
this_lag <- 5

var_fit <- vars::VAR(y = var_data, p = this_lag, type = "const")
```

### Proposing various lag values

For searching purposes we could propose a single maximum lag value, like 5, or a manually specify set of values, as 
c(3,5,6) or use some information-based criteria or add both approaches. 
The function lags_for_var, in this package, helps us to do just that. 

```{r proposing lags}
manual_single <- lags_for_var(vec_lags = 5, max_p_for_estimation = 9, endodata = var_data)

manual_multiple <- lags_for_var(vec_lags = c(5, 7), max_p_for_estimation = 9, endodata = var_data)

info_based <- lags_for_var(vec_lags = "info", max_p_for_estimation = 9, endodata = var_data)

manual_and_info <- lags_for_var(vec_lags = c(5, 7), add_info_based_lags = TRUE, max_p_for_estimation = 9, endodata = var_data)

print(manual_single)
print(manual_multiple)
print(info_based)
print(manual_and_info)
```

If we only specify manual values it will simply return the same value or vector, but if we chose "info" or "add_info_based_lags = TRUE" it will compute Akaike, Bayesian, SC and FPE criteria and choose the optimal lag for each of them, eliminate repeated values and return the resultig vector or its union with a manually specified vector of lags.


Then we do the following:

-  First, possibly set some coffiecients to zero. In practice, coefficients that are large in magnitude by statistically insignificant can cause instability (in the sense of causing roots of modulus greater than one), so we try some restricted models in addition to the initial one. Currently such restrictions are based of the t-values of each coefficients.

- The next step consist in computing the roots of the characteristic polynomial and discard all unstable VARs

- Surviving models are subject to a portmanteau test of their residuals, discarding models where the null of white noise of the residuals is rejected

Let's carry the steps above.

```{r some_tests}
var_fit_u <- vars::VAR(y = var_data, p = this_lag , type = "const")
var_fit_r_165 <- restrict(var_fit_u, method = "ser", thresh = 1.65)
var_fit_r_200 <- restrict(var_fit_u, method = "ser", thresh = 2)
```





