---
title: "The basics, with two models"
author: "Ricardo Mayer"
date: "12/6/2018"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_knit$set(root.dir = rprojroot::find_rstudio_root_file())
```

```{r source-and-lib, message=FALSE, warning=FALSE}
source('./R/combinations_functions.R')
```



We will start with a ready to use data set with quarterly, stationary series than can be used in an ordinary VAR, and we will not explain how the data munging is done. In particular, we will *not* discuss the following important points:
    - how the data was obtained
    - how monthly data was converted to quaterly frequency
    - how monthly data was *extended* to complete its current final quarter
    - how (potentially) exogenous data was forecasted in order to make it available to produce conditional forecasts
    - how each series was transformed using seasonal and oridinary differeces to render them stationary
    
All those points are discussed in the data preparation document, see *here*

## VAR-ready data set
    
We will use domestic data from Uruguay and few series that can be considered exogenous to teh country's economic activity, namely indexes of economic activity in USA, EU, Asia, Brazil and Argentina (we can choose later whether to treat a given series as exogeous or exogenous when specifying our VARs)

First, we identify the country (Uruguay) and vintage (second vintage of data gathered in 2018) Then we load the data, put it in quarterly form and print their names 


```{r loading_data}
country <- "Uruguay"
forecast_exercise_year <- 2018
forecast_exercise_number <- 3
var_output_path <- paste0("./analysis/VAR_output//edd_exercises/", forecast_exercise_year, 
                            "_exercise_", forecast_exercise_number, "/")

all_data_for_VAR_estimation  <- readRDS(paste0(var_output_path, "VAR_data_", country, ".rds"))
# print(colnames(VAR_data_for_estimation))
```

In this case, we used a  "diff-yoy" transformation for the real GDP series (first, take seasonal differences on the quarterly series and then ordinary differences on the result) and, as consequence the predictions about real gdp coming straight out the VAR will be forecasts in this metric, too. It is up to us to transform those predicted values into, say, year-on-year proportional changes.    

## Propose, test and keep or discard specifications

Given a data set with stationary variables, obteined in the previous section, a VAR especification consists in a set of endogenous variables, exogenous variables, a maximum lag value and a restriction over coefficients. Lets begin with the following specification

  - set of endogenous variables: rgdp, imp_intermediate, rpc
  - set of exogenous variables: none  (we will add them later)
  - a value for the maximum lag: 5
  - a restriction over coefficients: none or, as we will see, setting our threshold to zero. 

```{r inital_var_specification}
subset_of_variables <- c("rgdp", "imp_intermediate", "rpc")
var_data <- all_data_for_VAR_estimation[, subset_of_variables]
var_data <- na.omit(var_data)
this_lag <- 5

var_fit <- vars::VAR(y = var_data, p = this_lag, type = "const")
```

### Proposing various lag values

For searching purposes we could propose a single maximum lag value, like 5, or a manually specify set of values, as 
c(3,5,6) or use some information-based criteria or add both approaches. 
The function lags_for_var, in this package, helps us to do just that. If we only specify manual values it will simply return the same value or vector, but if we chose "info" or "add_info_based_lags = TRUE" it will compute Akaike, Bayesian, SC and FPE criteria and choose the optimal lag for each of them, eliminate repeated values and return the resultig vector or its union with a manually specified vector of lags.

```{r proposing lags}
manual_single <- lags_for_var(vec_lags = 5, max_p_for_estimation = 9, endodata = var_data)

manual_multiple <- lags_for_var(vec_lags = c(5, 7), max_p_for_estimation = 9, endodata = var_data)

info_based <- lags_for_var(vec_lags = "info", max_p_for_estimation = 9, endodata = var_data, ret_info_results = TRUE)

manual_and_info <- lags_for_var(vec_lags = c(5, 7), add_info_based_lags = TRUE, max_p_for_estimation = 9, endodata = var_data)

print(manual_single)
print(manual_multiple)
print(info_based$info_criteria)
print(manual_and_info)
```
In this case, the Akaike statistic is minimized at nine lags, the Schwartz statistic at one lag and both the prediction error and hanna-quinn statistics are minimized at 4 lags. In principle, we could try all values from 1 to 9 or even higher, but, besides the costs of extra computatons a note of caution is due: unrestricted VARs tend to increase the number of coeffcients very rapidly with the maximum value of lags and given that some our data matrices can be relative short we should be wary of lag-happy specifications. For instance, the following code will estimates all VARs using from 1 to 12 lags and report to us the degrees of freedom of the residuals for each lag choice:

```{r}
var_fit_1_to_13 <-  map(1:13, ~ vars::VAR(y = var_data, p = . , type = "const"))

df_1_to_13 <- map_dbl(var_fit_1_to_13, c("varresult", "rgdp", "df.residual"))
names(df_1_to_13) <- 1:13
print(df_1_to_13)

```

So, for instance, with one lag we have 44 degrees of freedom but only 12 if we choose nine lags and it is not even possible to fit a model with 12 lags with the amount of data we have.

Let's try a value like $p = 4$ for the rest of our examples, but nothing preclude us to use several values, as in 
$p = 1, 2, \ldots 6$.


### Try some zero-restrictions 

Then we do the following:

-  First, possibly set some cofficients to zero. In practice, coefficients that are large in magnitude by statistically insignificant can cause instability (in the sense of causing roots of modulus greater than one), so we try some restricted models in addition to the initial one. Currently such restrictions are based of the t-values of each coefficients.

- The next step consist in computing the roots of the characteristic polynomial and discard all unstable VARs

- Surviving models are subject to a portmanteau test of their residuals, discarding models where the null of white noise of the residuals is rejected

Let's carry the steps above.

```{r some_tests}
var_fit_u <- vars::VAR(y = var_data, p = this_lag , type = "const")
var_fit_r_165 <- restrict(var_fit_u, method = "ser", thresh = 1.65)
var_fit_r_200 <- restrict(var_fit_u, method = "ser", thresh = 2)
```





