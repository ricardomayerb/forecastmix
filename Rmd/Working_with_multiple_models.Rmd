---
title: 'Multiple models: a two-models speedy case'
author: "Ricardo Mayer"
date: "12/6/2018"
output:
  html_document: default
  pdf_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_knit$set(root.dir = rprojroot::find_rstudio_root_file())
```

```{r source-and-lib, message=FALSE, warning=FALSE}
source('./R/combinations_functions.R')
```

We will start with a ready to use data set with quarterly, stationary series than can be used in an ordinary VAR, and we will not explain how the data munging is done. In particular, we will *not* discuss the following important points:
    - how the data was obtained
    - how monthly data was converted to quaterly frequency
    - how monthly data was *extended* to complete its current final quarter
    - how (potentially) exogenous data was forecasted in order to make it available to produce conditional forecasts
    - how each series was transformed using seasonal and oridinary differeces to render them stationary
    
All those points are discussed in the data preparation document, see *here*

## VAR-ready data set
    
We will use the example dataset with domestic series from Uruguay and few external series. The rds file contains the country's name, the transformation applied to rgdp to render it stationary and two data sets: the original or raw data and one ready to used in VAR estimation,  containing only stationary versions of the original series. 


```{r loading_data}
data_object_ury <- readRDS("./data/examples/example_data_ury.rds")
print(names(data_object_ury))
country <- data_object_ury$country_name
target_transformation <- data_object_ury$target_transformation
raw_data <- data_object_ury$raw_data
var_data <- data_object_ury$transformed_data
print(target_transformation)
```

In this case, all VARs will use a  "diff-yoy" transformation of the real GDP series (i.e. first, take seasonal differences on the quarterly series and then ordinary differences on the result).    


## Counting specifications

The total number of potential specifications depends on a number of factors:
 - number of variable combinations. Which in turn depends on:
    - the total number of variables in the data set
    - the number of variables in the VAR (the "size" of the VAR: 2, 3, 4 ...)
    - the number of exogenous variables in the data set. This is because we generally choose leave out VARs where there is only one endogenous variable and all the rest are exogenous. That's more properly called an ARIMAX model. The default is to ignore such models when they show up, but it can be changed.
 - number of maximum lags to consider: e.g. 3, 4, 5 and 6
 - number of restricted version to consider: unrestricted, t = 1.65 and t = 2
 
 With two restricted version, plus the unrestricted one and four possible lag choices, we generate 12 specification per each variable combination we submit. A more modest inquiry may examine only unrestricted models for two lag choices, in which case ge only generate 2 specifications per tuple of variables. Say we have 500 combinations of variables to try out, that would tipically imply between 2x500 = 1000 and 12x500 = 6000 specifications to estimate, test and do cross-validation. 
 
A formula of the number of combinations, ignoring the distinction between endogenous and exogenpus variables, can be written as:

$$ncomb = \frac{(n - n_f)!}{(n - n_f - s - n_f)! ~ (s-n_f)!} = \frac{(n_a)!}{(n_a - s_a)! ~ (s_a)!}$$

Where $n$ is the total number of variables in the data set, $s$ is the number of distinct variables in the VAR (the "size") and $n_f$ is the number of *fixed variables*, i.e. those that need to be in any VAR (tipically $rgdp$ in our examples but it is *always* an endogenous variable and since we have at least one target variable it is at least equal to one). It can be more succintly expressed in the number of adjusted (for combinatorial purposes) numbers of variables to choose from,  $n_a := n -n_f$, and the adjusted  numbers of slots to fill, $s_a := s - n_f$. 

If we wanted to exclude those VAR with just one endogenous variables, then we can adjust $ncomb$ above by this quantity (notice that this case can only happen when we have only one endogenous variable acting as fixed variable):

$$ncomb_x = \frac{n_x!}{(n_x - (s-1))! ~ (s-1)!}$$
Where $n_x$ is the number of variables that we consider as exogenous. Notice that this number is zero in whenever there is less objects to choose from than the number of slots to be fill i.e when $n_x < s-1$.

Finally, we could define

$$ncomb^* = ncomb - ncomb_x$$

as the number of combinations, adjusted by ignoring VARs with only one endogenous variables. The table below shows, however that for the case of Uruguay (and it will be the case for the rest of our countries) it makes very little difference in the final number of variable combinations.
 

```{r countingcombinations}


ncombs <- map(2:7, ~ count_combn(var_size = .x, n_total = 31, n_exo = 6, n_fixed = 1))
ntable <- as_tibble(cbind(n = ncol(var_data), n_fixed = 1, size = 2:7, reduce(ncombs, rbind)))
print(ntable)

# ncombs41 <- map(2:7, ~ count_combn(var_size = .x, n_total = 41, n_exo = 6, n_fixed = 1))
# ntable41 <- as_tibble(cbind(n = ncol(var_data), n_fixed = 1, size = 2:7, reduce(ncombs41, rbind)))
# print(ntable41)
# 
# ncombs10 <- map(2:7, ~ count_combn(var_size = .x, n_total = 10, n_exo = 6, n_fixed = 1))
# ntable10 <- as_tibble(cbind(n = ncol(var_data), n_fixed = 1, size = 2:7, reduce(ncombs10, rbind)))
# print(ntable10)
```

 
Notice how rapidly the number of combinations increases with VAR size. Since $comb_x$ is relatively small here, for the next table we will consider $ncomb$ alone. Depending on the number of different lags and restrictions the final number of specification will tipically  be from two (no restrictions and two lag choices) to twelve times (two restrictions and four lag choices) the number of variable combinations. In the following table we consider the resulting number of specification under those two scenarios plus the number of estimations made taking into account ten rounds of cross validations in addition to the full sample original estimate. Since at least some models will fail the tests, only a fraction of them will qualify to be passed to cross-validation. The table below assume that between 20 to 90 percent of the models will pass. So the minimum number of VAR estimation to do happens in the no-restriction, two lag choices and 20% of qulifiying, whereas the maximum number of estimation would happens if 90% of the models pass the test and we are trying four lag choices and two restrictions.


```{r nspecifications}

nspectable <- ntable %>% dplyr::select(size, ncomb)

nspectable <- nspectable %>% 
  mutate(nVAR_2 = ncomb*2, nVAR_12 = ncomb*12, cv_min = nVAR_2*0.2*10, cv_max = nVAR_12*0.9*10)

print(nspectable)


```

Even with a modest size of 4, we can be dealing with 50,000 specification (and tests) and almost half a million estimations. Projecting how long those estimatiation would take, needs to consider that restricted estimations are slower than unrestrited ones and we will leave that for later. By this time we just want to notice that in order to use VAR of size 5 we either confine ourselves to unrestricted models and few lag choices or we need to find a strategy to select variables that lowers the number of possible combinations to be explored.

To expede wthing up in this document we will restrict oour attention to size-3 VARs, usig at first two variable combinations and at the end using all of them.



## Generate all specifications for a given size



```{r tuplesofvbls}
var_size <- 3 
all_variables <- colnames(var_data)
target_variable <- "rgdp"
non_target_fixed <- c("")

# 1742
tic()
specifications_size_3_big <- all_specifications(
  var_size = 3, all_variables = colnames(var_data),
  lag_choices = c(3,4,5), use_info_lags = TRUE,
  var_data = var_data, t_thresholds = c(1.65, 2))
toc()


# 14933
tic()
specifications_size_4_big <- all_specifications(
  var_size = 4, all_variables = colnames(var_data), 
  lag_choices = c(3,4,5), use_info_lags = TRUE, 
  var_data = var_data, t_thresholds = c(1.65, 2), silent = TRUE)
toc()


# 1305
tic()
specifications_size_3_big_noinfolag <- all_specifications(
  var_size = 3, all_variables = colnames(var_data), 
  lag_choices = c(3,4,5), use_info_lags = FALSE, 
  var_data = var_data, t_thresholds = c(1.65, 2))
toc()

# 12180
tic()
specifications_big_noinfolags_size4 <- all_specifications(
  var_size = 4, all_variables = colnames(var_data), 
  lag_choices = c(3,4,5), use_info_lags = FALSE, 
  var_data = var_data, t_thresholds = c(1.65, 2))
toc()


```

### Select a subset of specification for expediency in this document
```{r}

specifications_size_3_small <- specifications_size_3_big[1:17, ] 
specifications_size_3_medium <- specifications_size_3_big[1:170, ] 

specifications_size_4_small <- specifications_size_4_big[1:17, ] 
specifications_size_4_medium <- specifications_size_4_big[1:170, ] 

```


## Fit all specifications and keep only acceptable ones

```{r  passing_models_size3small}
ftmt_size_3_small <- fit_tests_models_table(specifications_size_3_small, var_data = var_data)

pm_size_3_small <- ftmt_size_3_small[["passing_models"]]
print(head(pm_size_3_small))

ftmt_size_3_medium <- fit_tests_models_table(specifications_size_3_medium, var_data = var_data)
pm_size_3_medium <- ftmt_size_3_medium[["passing_models"]]

# ftmt_size_3_big <- fit_tests_models_table(specifications_size_3_big, var_data = var_data)
# pm_size_3_big <- ftmt_size_3_big[["passing_models"]]

```


## Time Series Cross Validation on valid specifications

```{r tscv_s3small}
fc_horizon <- 8
n_cv <- 10
# training_length <- 30
training_length <- "per_cv_maxs" 
fit_column <- "fit"
target_transform <- target_transformation
target_level_ts <- na.omit(raw_data[, target_variable])

tic()
cv_size_3_small <- cv_var_from_model_tbl(h = fc_horizon,
                             training_length = training_length, 
                             n_cv = n_cv,
                             models_tbl = pm_size_3_small, 
                             var_data = var_data, 
                             fit_column = "fit", 
                             target_transform = target_transform,
                             target_level_ts = target_level_ts,
                             )
toc()

tic()
cv_size_3_medium <- cv_var_from_model_tbl(h = fc_horizon,
                             training_length = training_length, 
                             n_cv = n_cv,
                             models_tbl = pm_size_3_medium, 
                             var_data = var_data, 
                             fit_column = "fit", 
                             target_transform = target_transform,
                             target_level_ts = target_level_ts,
                             )
toc() 

# tic()
# cv_size_3_big <- cv_var_from_model_tbl(h = fc_horizon,
#                              training_length = training_length, 
#                              n_cv = n_cv,
#                              models_tbl = pm_size_3_big, 
#                              var_data = var_data, 
#                              fit_column = "fit", 
#                              target_transform = target_transform,
#                              target_level_ts = target_level_ts,
#                              )
# toc()
#  
# os1 <- object.size(pm_size_3_big)
# os2 <- object.size(cv_size_3_big)
# os1/os2

```



## Combine forecasts based on performance measure


```{r forecast_using_cv}

# rank and filter

max_rank_h <- 5

surviving_names <- cv_size_3_small %>% 
  gather(key = "rmse_h", value = "rmse", 
         vars_select(names(.), starts_with("rmse"))) %>% 
  group_by(rmse_h) %>% 
  mutate(rank_h = rank(rmse)) %>% 
  filter(rank_h <= max_rank_h) %>% 
  ungroup() %>% 
  dplyr::select(short_name) %>% 
  distinct()

rank_filtered_models <- semi_join(cv_size_3_small, surviving_names, by = "short_name")

# use all models
fc_s3_small <- forecast_var_from_model_tbl(
  rank_filtered_models, var_data, fc_horizon, 
  target_transform = target_transform,
  target_level_ts = target_level_ts, do_tests = FALSE, both_rest_unrest = TRUE) 





```


<!-- ## Computing time and object size -->

<!-- ### Restricted versus unrestricted -->

<!-- ### Overall number of models -->

<!-- ### Size 3 versus size 4 -->

<!-- ```{r ftmt_size_3_smb} -->

<!-- tic() -->
<!-- ftmt_size_3_small <- fit_tests_models_table(specifications_size_3_small, var_data = var_data) -->
<!-- toc() -->
<!-- pm_size_3_small <- ftmt_size_3_small[["passing_models"]] -->

<!-- ftmt_size_3_small_no_fit <- fit_tests_models_table(specifications_size_3_small, var_data = var_data, -->
<!--                                 keep_fit = FALSE) -->
<!-- pm_size_3_small_no_fit <- ftmt_size_3_small_no_fit[["passing_models"]] -->


<!-- tic() -->
<!-- ftmt_size_3_medium <- fit_tests_models_table(specifications_size_3_medium, var_data = var_data) -->
<!-- toc() -->
<!-- pm_size_3_medium <- ftmt_size_3_medium[["passing_models"]] -->


<!-- # ftmt_size_3_medium_no_fit <- fit_tests_models_table(specifications_size_3_medium, var_data = var_data,   keep_fit = FALSE) -->
<!-- # pm_size_3_medium_no_fit <- ftmt_size_3_medium_no_fit[["passing_models"]] -->

<!-- # tic() -->
<!-- # ftmt_size_3_big_no_fit <- fit_tests_models_table(specifications_size_3_big, var_data = var_data,   keep_fit = FALSE) -->
<!-- # toc() -->
<!-- # pm_size_3_big_no_fit <- ftmt_size_3_big_no_fit[["passing_models"]] -->


<!-- ``` -->




<!-- ```{r ftmt_size_4_smb} -->

<!-- tic() -->
<!-- ftmt_size_4_small <- fit_tests_models_table(specifications_size_4_small, var_data = var_data) -->
<!-- toc() -->
<!-- pm_size_4_small <- ftmt_size_4_small[["passing_models"]] -->

<!-- ftmt_size_4_small_no_fit <- fit_tests_models_table(specifications_size_4_small, var_data = var_data, -->
<!--                                 keep_fit = FALSE) -->
<!-- pm_size_4_small_no_fit <- ftmt_size_4_small_no_fit[["passing_models"]] -->


<!-- tic() -->
<!-- ftmt_size_4_medium <- fit_tests_models_table(specifications_size_4_medium, var_data = var_data) -->
<!-- toc() -->
<!-- pm_size_4_medium <- ftmt_size_4_medium[["passing_models"]] -->


<!-- # ftmt_size_4_medium_no_fit <- fit_tests_models_table(specifications_size_4_medium, var_data = var_data,   keep_fit = FALSE) -->
<!-- # pm_size_4_medium_no_fit <- ftmt_size_4_medium_no_fit[["passing_models"]] -->

<!-- # tic() -->
<!-- # ftmt_size_4_big_no_fit <- fit_tests_models_table(specifications_size_4_big, var_data = var_data,   keep_fit = FALSE) -->
<!-- # toc() -->
<!-- # pm_size_4_big_no_fit <- ftmt_size_4_big_no_fit[["passing_models"]] -->


<!-- ``` -->


